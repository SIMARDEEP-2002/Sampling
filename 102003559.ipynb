{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "# import train_test_split\n",
                "from sklearn.model_selection import train_test_split\n",
                "# import accuracy_score\n",
                "from sklearn.metrics import accuracy_score\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# read the csv file\n",
                "df = pd.read_csv('Creditcard_data.csv')\n",
                "# standardize the amount and time columns\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "df['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
                "df['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=0.3, random_state=42)\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1    534\n",
                            "0    534\n",
                            "Name: Class, dtype: int64"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# balance the training data using oversampling\n",
                "from imblearn.over_sampling import SMOTE\n",
                "sm = SMOTE(random_state=42)\n",
                "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
                "# create a data frame having X_train and Y_train\n",
                "df_train = pd.concat([X_train, y_train], axis=1)\n",
                "# know about 31st column of the data frame\n",
                "df_train.iloc[:, 30].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def random_sampling(df, sample_size):\n",
                "\n",
                "    df_sample = df.sample(n=sample_size, random_state=1)\n",
                "    return df_sample\n",
                "\n",
                "# create a function for systematic sampling\n",
                "\n",
                "def systematic_sampling(data, sample_size):\n",
                "    # Calculate the sampling interval\n",
                "    n = len(data)\n",
                "    k = np.ceil(n / sample_size)\n",
                "    \n",
                "    # Create the indices for the sample\n",
                "    indices = np.arange(0, n, k)\n",
                "    \n",
                "    # Sample the data\n",
                "    sample = data.iloc[indices[:sample_size]]\n",
                "    \n",
                "    return sample\n",
                "\n",
                "# create a function for stratified sampling\n",
                "\n",
                "\n",
                "from sklearn.model_selection import StratifiedShuffleSplit\n",
                "\n",
                "def stratified_sampling(df, sample_size):\n",
                "  \n",
                "    target_col = df.columns[-1]\n",
                "    strata_cols = df.columns[:-1]\n",
                "\n",
                "    # Create a StratifiedShuffleSplit object\n",
                "    sss = StratifiedShuffleSplit(n_splits=1, test_size=sample_size, random_state=42)\n",
                "\n",
                "    # Apply the StratifiedShuffleSplit to the entire DataFrame\n",
                "    X = df.drop(target_col, axis=1)\n",
                "    y = df[target_col]\n",
                "    for train_index, test_index in sss.split(X, y):\n",
                "        sampled_df = df.iloc[test_index]\n",
                "\n",
                "    return sampled_df\n",
                "\n",
                "\n",
                "# create a function for cluster sampling\n",
                "\n",
                "def cluster_sampling(data, sample_size):\n",
                "    # Calculate the number of clusters\n",
                "    n = len(data)\n",
                "    k = np.ceil(n / sample_size)\n",
                "    \n",
                "    # Calculate the cluster size\n",
                "    cluster_size = np.ceil(n / k)\n",
                "    \n",
                "    # Create the clusters\n",
                "    clusters = [data.iloc[int(i * cluster_size):int((i + 1) * cluster_size)] for i in range(int(k))]\n",
                "    \n",
                "    # Sample the clusters\n",
                "    sample = pd.concat([cluster.sample(n=1, random_state=42) for cluster in clusters])\n",
                "    \n",
                "    return sample\n",
                "\n",
                "# create a function for weighted sampling\n",
                "\n",
                "def weighted_sampling(data, sample_size):\n",
                "    # Create the weighted sample\n",
                "    sample = data.groupby('Class', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size)))\n",
                "    \n",
                "    return sample\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "def random_sample_size():\n",
                "    z=1.96\n",
                "    p=0.5\n",
                "    e=0.05\n",
                "    n=(z**2*p*(1-p))/(e**2)\n",
                "    return int(n)\n",
                "\n",
                "\n",
                "def systematic_sample_size_z(population_size):\n",
                "    # Calculate the population standard deviation (we assume we don't know it)\n",
                "    p= 0.5  \n",
                "    z=1.96\n",
                "    e=0.05\n",
                "  # Calculate the sample size\n",
                "    n = (z**2 * population_size * p * (1 - p)) / ((z**2 * p * (1 - p)) + ((e / 2)**2 * (population_size - 1)))\n",
                "    return int(n)\n",
                "\n",
                "def stratified_sampling_size():\n",
                "    z=1.96\n",
                "    p=0.5\n",
                "    e=0.15\n",
                "    s=2\n",
                "    q=e/s\n",
                "    n=(z**2*p*(1-p))/(q**2)\n",
                "    return int(n)\n",
                "\n",
                "def cluster_sampling_size():\n",
                "    z=1.96\n",
                "    p=0.5\n",
                "    e=0.15\n",
                "    c=2\n",
                "    q=e/c\n",
                "    n=(z**2*p*(1-p))/(q**2)\n",
                "    return int(n)\n",
                "\n",
                "def weighted_sampling_size():\n",
                "    z=1.96\n",
                "    p=0.5\n",
                "    e=0.15\n",
                "    n=(z**2*p*(1-p))/(e**2)\n",
                "    return int(n)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "384\n",
                        "(384, 31)\n",
                        "(356, 31)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/simar/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
                        "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
                        "/Users/simar/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
                        "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>models</th>\n",
                            "      <th>Sampling1</th>\n",
                            "      <th>Sampling2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>LogisticRegression</td>\n",
                            "      <td>0.875000</td>\n",
                            "      <td>0.887931</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>DecisionTreeClassifier</td>\n",
                            "      <td>0.943966</td>\n",
                            "      <td>0.948276</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>RandomForestClassifier</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.982759</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>SVM</td>\n",
                            "      <td>0.918103</td>\n",
                            "      <td>0.909483</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>KNeighborsClassifier</td>\n",
                            "      <td>0.818966</td>\n",
                            "      <td>0.801724</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                   models  Sampling1  Sampling2\n",
                            "0      LogisticRegression   0.875000   0.887931\n",
                            "1  DecisionTreeClassifier   0.943966   0.948276\n",
                            "2  RandomForestClassifier   0.982759   0.982759\n",
                            "3                     SVM   0.918103   0.909483\n",
                            "4    KNeighborsClassifier   0.818966   0.801724"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# apply random sampling\n",
                "df_random = random_sampling(df_train, random_sample_size())\n",
                "print(random_sample_size())\n",
                "print(df_random.shape)\n",
                "# apply systematic sampling\n",
                "df_systematic = systematic_sampling(df_train, systematic_sample_size_z(len(df)))\n",
                "print(df_systematic.shape)\n",
                "\n",
                "# apply 5 ml models on df_random\n",
                "# import the models\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "# from sklearn.naive_bayes import GaussianNB\n",
                "df_result=pd.DataFrame()\n",
                "models=['LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','SVM','KNeighborsClassifier']\n",
                "df_result['models']=models\n",
                "list_accuracy=[]\n",
                "\n",
                "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(df_random.drop('Class', axis=1), df_random['Class'], test_size=0.0000001, random_state=42)\n",
                "\n",
                "# apply logistic regression \n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train_r, y_train_r)\n",
                "# accuracy score\n",
                "#round to score 2 decimal places and append to list_accuracy\n",
                "list_accuracy.append(lr.score(X_test, y_test))\n",
                "\n",
                "# apply decision tree\n",
                "dt = DecisionTreeClassifier()\n",
                "dt.fit(X_train_r, y_train_r)\n",
                "list_accuracy.append(dt.score(X_test, y_test))\n",
                "\n",
                "# apply random forest\n",
                "rf = RandomForestClassifier()\n",
                "rf.fit(X_train_r, y_train_r)\n",
                "list_accuracy.append(rf.score(X_test, y_test))\n",
                "\n",
                "# apply svm\n",
                "svm = SVC()\n",
                "svm.fit(X_train_r, y_train_r)\n",
                "list_accuracy.append(svm.score(X_test, y_test))\n",
                "\n",
                "# apply knn\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train_r, y_train_r)\n",
                "list_accuracy.append(knn.score(X_test, y_test))\n",
                "\n",
                "df_result['Sampling1']=list_accuracy\n",
                "list_accuracy=[]\n",
                "\n",
                "# apply 5 ml models on df_systematic\n",
                "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(df_systematic.drop('Class', axis=1), df_systematic['Class'], test_size=0.0000001, random_state=42)\n",
                "\n",
                "# apply logistic regression\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train_s, y_train_s)\n",
                "list_accuracy.append(lr.score(X_test, y_test))\n",
                "\n",
                "# apply decision tree\n",
                "dt = DecisionTreeClassifier()\n",
                "dt.fit(X_train_s, y_train_s)\n",
                "list_accuracy.append(dt.score(X_test, y_test))\n",
                "\n",
                "# apply random forest\n",
                "rf = RandomForestClassifier()\n",
                "rf.fit(X_train_s, y_train_s)\n",
                "list_accuracy.append(rf.score(X_test, y_test))\n",
                "\n",
                "# apply svm\n",
                "svm = SVC()\n",
                "svm.fit(X_train_s, y_train_s)\n",
                "list_accuracy.append(svm.score(X_test, y_test))\n",
                "\n",
                "# apply knn\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train_s, y_train_s)\n",
                "list_accuracy.append(knn.score(X_test, y_test))\n",
                "\n",
                "df_result['Sampling2']=list_accuracy\n",
                "df_result\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/simar/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
                        "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>models</th>\n",
                            "      <th>Sampling1</th>\n",
                            "      <th>Sampling2</th>\n",
                            "      <th>Sampling3</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>LogisticRegression</td>\n",
                            "      <td>0.875000</td>\n",
                            "      <td>0.887931</td>\n",
                            "      <td>0.866379</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>DecisionTreeClassifier</td>\n",
                            "      <td>0.943966</td>\n",
                            "      <td>0.948276</td>\n",
                            "      <td>0.961207</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>RandomForestClassifier</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.987069</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>SVM</td>\n",
                            "      <td>0.918103</td>\n",
                            "      <td>0.909483</td>\n",
                            "      <td>0.913793</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>KNeighborsClassifier</td>\n",
                            "      <td>0.818966</td>\n",
                            "      <td>0.801724</td>\n",
                            "      <td>0.715517</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                   models  Sampling1  Sampling2  Sampling3\n",
                            "0      LogisticRegression   0.875000   0.887931   0.866379\n",
                            "1  DecisionTreeClassifier   0.943966   0.948276   0.961207\n",
                            "2  RandomForestClassifier   0.982759   0.982759   0.987069\n",
                            "3                     SVM   0.918103   0.909483   0.913793\n",
                            "4    KNeighborsClassifier   0.818966   0.801724   0.715517"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# apply stratified sampling\n",
                "df_stratified = stratified_sampling(df_train, stratified_sampling_size())\n",
                "list_accuracy=[]\n",
                "\n",
                "#apply 5 ml models on df_stratified\n",
                "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(df_stratified.drop('Class', axis=1), df_stratified['Class'], test_size=0.0000001, random_state=42)\n",
                "\n",
                "# apply logistic regression\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train_st, y_train_st)\n",
                "list_accuracy.append(lr.score(X_test, y_test))\n",
                "\n",
                "# apply decision tree\n",
                "dt = DecisionTreeClassifier()\n",
                "dt.fit(X_train_st, y_train_st)\n",
                "list_accuracy.append(dt.score(X_test, y_test))\n",
                "\n",
                "# apply random forest\n",
                "rf = RandomForestClassifier()\n",
                "rf.fit(X_train_st, y_train_st)\n",
                "list_accuracy.append(rf.score(X_test, y_test))\n",
                "\n",
                "# apply svm\n",
                "svm = SVC()\n",
                "svm.fit(X_train_st, y_train_st)\n",
                "list_accuracy.append(svm.score(X_test, y_test))\n",
                "\n",
                "# apply knn\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train_st, y_train_st)\n",
                "list_accuracy.append(knn.score(X_test, y_test))\n",
                "\n",
                "df_result['Sampling3']=list_accuracy\n",
                "df_result\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/simar/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
                        "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>models</th>\n",
                            "      <th>Sampling1</th>\n",
                            "      <th>Sampling2</th>\n",
                            "      <th>Sampling3</th>\n",
                            "      <th>Sampling4</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>LogisticRegression</td>\n",
                            "      <td>0.875000</td>\n",
                            "      <td>0.887931</td>\n",
                            "      <td>0.866379</td>\n",
                            "      <td>0.077586</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>DecisionTreeClassifier</td>\n",
                            "      <td>0.943966</td>\n",
                            "      <td>0.948276</td>\n",
                            "      <td>0.961207</td>\n",
                            "      <td>0.547414</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>RandomForestClassifier</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.987069</td>\n",
                            "      <td>0.034483</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>SVM</td>\n",
                            "      <td>0.918103</td>\n",
                            "      <td>0.909483</td>\n",
                            "      <td>0.913793</td>\n",
                            "      <td>0.012931</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>KNeighborsClassifier</td>\n",
                            "      <td>0.818966</td>\n",
                            "      <td>0.801724</td>\n",
                            "      <td>0.715517</td>\n",
                            "      <td>0.012931</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                   models  Sampling1  Sampling2  Sampling3  Sampling4\n",
                            "0      LogisticRegression   0.875000   0.887931   0.866379   0.077586\n",
                            "1  DecisionTreeClassifier   0.943966   0.948276   0.961207   0.547414\n",
                            "2  RandomForestClassifier   0.982759   0.982759   0.987069   0.034483\n",
                            "3                     SVM   0.918103   0.909483   0.913793   0.012931\n",
                            "4    KNeighborsClassifier   0.818966   0.801724   0.715517   0.012931"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# apply cluster sampling\n",
                "df_cluster = cluster_sampling(df_train, cluster_sampling_size())\n",
                "list_accuracy=[]\n",
                "#apply 5 ml models on df_cluster\n",
                "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(df_cluster.drop('Class', axis=1), df_cluster['Class'], test_size=0.0000001, random_state=42)\n",
                "\n",
                "# apply logistic regression\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train_c, y_train_c)\n",
                "list_accuracy.append(lr.score(X_test, y_test))\n",
                "\n",
                "# apply decision tree\n",
                "dt = DecisionTreeClassifier()\n",
                "dt.fit(X_train_c, y_train_c)\n",
                "list_accuracy.append(dt.score(X_test, y_test))\n",
                "\n",
                "# apply random forest\n",
                "rf = RandomForestClassifier()\n",
                "rf.fit(X_train_c, y_train_c)\n",
                "list_accuracy.append(rf.score(X_test, y_test))\n",
                "\n",
                "# apply svm\n",
                "svm = SVC()\n",
                "svm.fit(X_train_c, y_train_c)\n",
                "list_accuracy.append(svm.score(X_test, y_test))\n",
                "\n",
                "# apply knn\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train_c, y_train_c)\n",
                "list_accuracy.append(knn.score(X_test, y_test))\n",
                "\n",
                "df_result['Sampling4']=list_accuracy\n",
                "df_result\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/simar/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
                        "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>models</th>\n",
                            "      <th>Sampling1</th>\n",
                            "      <th>Sampling2</th>\n",
                            "      <th>Sampling3</th>\n",
                            "      <th>Sampling4</th>\n",
                            "      <th>Sampling5</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>LogisticRegression</td>\n",
                            "      <td>0.875000</td>\n",
                            "      <td>0.887931</td>\n",
                            "      <td>0.866379</td>\n",
                            "      <td>0.077586</td>\n",
                            "      <td>0.767241</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>DecisionTreeClassifier</td>\n",
                            "      <td>0.943966</td>\n",
                            "      <td>0.948276</td>\n",
                            "      <td>0.961207</td>\n",
                            "      <td>0.547414</td>\n",
                            "      <td>0.836207</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>RandomForestClassifier</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.982759</td>\n",
                            "      <td>0.987069</td>\n",
                            "      <td>0.034483</td>\n",
                            "      <td>0.943966</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>SVM</td>\n",
                            "      <td>0.918103</td>\n",
                            "      <td>0.909483</td>\n",
                            "      <td>0.913793</td>\n",
                            "      <td>0.012931</td>\n",
                            "      <td>0.827586</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>KNeighborsClassifier</td>\n",
                            "      <td>0.818966</td>\n",
                            "      <td>0.801724</td>\n",
                            "      <td>0.715517</td>\n",
                            "      <td>0.012931</td>\n",
                            "      <td>0.469828</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                   models  Sampling1  Sampling2  Sampling3  Sampling4  \\\n",
                            "0      LogisticRegression   0.875000   0.887931   0.866379   0.077586   \n",
                            "1  DecisionTreeClassifier   0.943966   0.948276   0.961207   0.547414   \n",
                            "2  RandomForestClassifier   0.982759   0.982759   0.987069   0.034483   \n",
                            "3                     SVM   0.918103   0.909483   0.913793   0.012931   \n",
                            "4    KNeighborsClassifier   0.818966   0.801724   0.715517   0.012931   \n",
                            "\n",
                            "   Sampling5  \n",
                            "0   0.767241  \n",
                            "1   0.836207  \n",
                            "2   0.943966  \n",
                            "3   0.827586  \n",
                            "4   0.469828  "
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# apply weighted sampling\n",
                "df_weighted = weighted_sampling(df_train, weighted_sampling_size())\n",
                "list_accuracy=[]\n",
                "\n",
                "#apply 5 ml models on df_weighted\n",
                "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(df_weighted.drop('Class', axis=1), df_weighted['Class'], test_size=0.0000001, random_state=42)\n",
                "\n",
                "# apply logistic regression\n",
                "lr = LogisticRegression()\n",
                "lr.fit(X_train_w, y_train_w)\n",
                "list_accuracy.append(lr.score(X_test, y_test))\n",
                "\n",
                "# apply decision tree\n",
                "dt = DecisionTreeClassifier()\n",
                "dt.fit(X_train_w, y_train_w)\n",
                "list_accuracy.append(dt.score(X_test, y_test))\n",
                "\n",
                "# apply random forest\n",
                "rf = RandomForestClassifier()\n",
                "rf.fit(X_train_w, y_train_w)\n",
                "list_accuracy.append(rf.score(X_test, y_test))\n",
                "\n",
                "# apply svm\n",
                "svm = SVC()\n",
                "svm.fit(X_train_w, y_train_w)\n",
                "list_accuracy.append(svm.score(X_test, y_test))\n",
                "\n",
                "# apply knn\n",
                "knn = KNeighborsClassifier()\n",
                "knn.fit(X_train_w, y_train_w)\n",
                "list_accuracy.append(knn.score(X_test, y_test))\n",
                "\n",
                "df_result['Sampling5']=list_accuracy\n",
                "df_result"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "951e5670e6a77f246625927674f9b2309ae610b0b123b471b6d07ec58ee7dfe8"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
